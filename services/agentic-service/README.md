# ğŸš€ Agentic Service - Document Processing & AI Vectorization

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green.svg)](https://fastapi.tiangolo.com)
[![AWS](https://img.shields.io/badge/AWS-Lambda%20%7C%20S3%20%7C%20OpenSearch-orange.svg)](https://aws.amazon.com)

> **Beautiful, modular, and production-ready** document processing service that transforms files into AI-searchable vectors using OpenAI embeddings and AWS infrastructure.

## âœ¨ What This Service Does

Transform documents into intelligent, searchable vectors:
- ğŸ“„ **Process Documents**: PDF, DOCX, TXT, MD, PPTX, XLSX files
- ğŸ§  **Create Embeddings**: Using OpenAI's latest embedding models
- ğŸ” **Store & Search**: In AWS OpenSearch for lightning-fast retrieval
- â˜ï¸ **Cloud Ready**: Runs on AWS Lambda or locally
- ğŸ¯ **Production Grade**: Clean architecture, comprehensive testing, monitoring

## ğŸ—ï¸ Clean Architecture

### Before: 961-line Monster ğŸ˜±
- Single massive file with mixed concerns
- Hard to test, maintain, and understand

### After: Beautiful, Modular Design ğŸ¨

```
src/
â”œâ”€â”€ ğŸ—ï¸  core/                     # Foundation utilities
â”‚   â”œâ”€â”€ logging.py                # Centralized logging
â”‚   â”œâ”€â”€ exceptions.py             # Custom exception hierarchy  
â”‚   â”œâ”€â”€ retry.py                  # Retry decorators
â”‚   â””â”€â”€ environment.py            # Environment detection
â”œâ”€â”€ ğŸ”§  infrastructure/           # External service clients
â”‚   â”œâ”€â”€ aws/
â”‚   â”‚   â”œâ”€â”€ s3_client.py          # S3 operations
â”‚   â”‚   â””â”€â”€ opensearch_client.py  # OpenSearch operations
â”‚   â””â”€â”€ openai/
â”‚       â””â”€â”€ client.py             # OpenAI client
â”œâ”€â”€ ğŸ¯  services/                 # Business logic
â”‚   â”œâ”€â”€ file_processor.py         # File processing
â”‚   â”œâ”€â”€ embedding_service.py      # Embedding creation
â”‚   â”œâ”€â”€ vectorization_service.py  # Complete pipeline
â”‚   â””â”€â”€ text_service.py           # Text processing utilities
â”œâ”€â”€ âš™ï¸   config/                  # Configuration
â”‚   â”œâ”€â”€ main_config.py            # Main configuration
â”‚   â””â”€â”€ file_config.py            # File processing config
â”œâ”€â”€ ğŸ“Š  models/                   # Data models
â”‚   â”œâ”€â”€ responses.py              # Response models
â”‚   â””â”€â”€ schemas/                  # Request/response schemas
â”œâ”€â”€ ğŸ®  controllers/              # Slim controllers
â”‚   â””â”€â”€ file_controller.py        # Orchestration (150 lines!)
â””â”€â”€ ğŸ›£ï¸   routers/                 # API routes
    â””â”€â”€ file_routes.py            # FastAPI routes
```

## ğŸš€ Quick Start

### 1. Prerequisites

```bash
# Python 3.11+
python --version

# Virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
venv\Scripts\activate     # Windows
```

### 2. Installation

```bash
# Clone and navigate
cd pathlight/services/agentic-service

# Install dependencies
pip install -r requirements.txt

# Copy environment template
cp .env.example .env
```

### 3. Environment Configuration

Edit `.env` file:

```bash
# Required - OpenAI
OPENAI_API_KEY=sk-your-openai-api-key

# Required - AWS (for S3 and OpenSearch)
ACCESS_KEY_ID=your-aws-access-key
SECRET_ACCESS_KEY=your-aws-secret-key
REGION=ap-northeast-1
S3_BUCKET_NAME=your-s3-bucket

# Optional - OpenSearch (auto-disabled locally)
OPENSEARCH_ENABLED=false  # Set to true for full functionality
OPENSEARCH_HOST=your-opensearch-endpoint
OPENSEARCH_USERNAME=your-username
OPENSEARCH_PASSWORD=your-password

# Development
ENVIRONMENT=local
LOG_LEVEL=INFO
```

### 4. Run the Service

```bash
# Development server with auto-reload
uvicorn src.main:app --reload --host 0.0.0.0 --port 8000

# Or using the startup script
python src/main.py
```

### 5. Test the API

```bash
# Health check
curl http://localhost:8000/health

# API documentation
open http://localhost:8000/docs
```

## ğŸ“š API Documentation

### ğŸ”„ File Processing

#### Upload & Vectorize Documents
```bash
POST /api/v1/vectorize
```

**Description**: Upload files and transform them into searchable vectors

**Request**:
```bash
curl -X POST "http://localhost:8000/api/v1/vectorize" \
  -H "Content-Type: multipart/form-data" \
  -F "files=@document.pdf" \
  -F "files=@presentation.pptx" \
  -F "material_id=course-101"
```

**Response**:
```json
{
  "status": "success",
  "message": "Files processed and vectorized successfully",
  "processed_files": [
    {
      "filename": "document.pdf",
      "chunks_created": 15,
      "content_length": 12543,
      "processing_time": 2.3
    }
  ],
  "total_vectors_created": 15,
  "processing_time": 4.7
}
```

#### List S3 Files
```bash
GET /api/v1/s3/files
```

#### Download File
```bash
GET /api/v1/s3/files/{filename}
```

### ğŸ¥ Health & Debugging

#### Health Check
```bash
GET /health
```

#### Configuration Info
```bash
GET /debug/config
```

## ğŸ› ï¸ Development Guide

### Architecture Patterns

#### 1. **Dependency Injection**
```python
class FileController:
    def __init__(self):
        # Services injected at runtime
        self.s3_client = self._create_s3_client()
        self.vectorization_service = VectorizationService(...)
```

#### 2. **Service Layer Pattern**
```python
class VectorizationService:
    """Orchestrates the complete file-to-vector pipeline"""
    def __init__(self, file_processor, embedding_service, opensearch_client):
        # Clean separation of concerns
```

#### 3. **Exception Hierarchy**
```python
from core.exceptions import (
    ValidationError,           # Input validation issues
    FileProcessingError,      # File processing problems
    EmbeddingCreationError,   # OpenAI embedding issues
    S3OperationError,         # S3 connectivity problems
    OpenSearchOperationError  # OpenSearch issues
)
```

### Adding New Features

#### 1. **New File Type Support**
```python
# In services/file_processor.py
def _extract_new_format(self, file_stream, filename):
    """Add your extraction logic here"""
    return extracted_content
```

#### 2. **New Storage Backend**
```python
# Create infrastructure/your_service/client.py
class YourServiceClient:
    """Implement the storage interface"""
    
    async def store_vector(self, vector_data):
        # Your implementation
```

#### 3. **New AI Service**
```python
# Create infrastructure/your_ai/client.py
class YourAIClient:
    """Implement the AI interface"""
    
    async def create_embedding(self, text):
        # Your implementation
```

### Testing

#### Run All Tests
```bash
# All tests
pytest

# With coverage
pytest --cov=src

# Specific test file
pytest tests/test_main.py -v

# Specific test
pytest tests/test_main.py::test_config_validation -v
```

#### Test Structure
```python
def test_file_processing():
    """Test individual components in isolation"""
    processor = FileProcessor(allowed_extensions=["pdf"])
    result = processor.process_single_file("test.pdf", file_stream)
    assert result.success
```

### Environment Modes

#### ğŸ  **Local Development**
- OpenSearch disabled by default
- File processing works without external dependencies
- Full logging and debugging

#### ğŸ³ **Container/Docker**
- Production-like environment
- All services enabled
- Optimized logging

#### â˜ï¸ **AWS Lambda**
- Serverless deployment
- Automatic environment detection
- Optimized for cold starts

#### ğŸ§ª **Testing**
- Mocked external services
- Fast execution
- Isolated test data

## ğŸ”§ Configuration

### Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `OPENAI_API_KEY` | âœ… | - | OpenAI API key for embeddings |
| `S3_BUCKET_NAME` | âœ… | - | AWS S3 bucket for file storage |
| `ACCESS_KEY_ID` | âœ… | - | AWS access key |
| `SECRET_ACCESS_KEY` | âœ… | - | AWS secret key |
| `REGION` | âŒ | `ap-northeast-1` | AWS region |
| `OPENSEARCH_ENABLED` | âŒ | `false` (local) | Enable OpenSearch |
| `OPENSEARCH_HOST` | âŒ | - | OpenSearch endpoint |
| `ENVIRONMENT` | âŒ | Auto-detect | Environment mode |
| `LOG_LEVEL` | âŒ | `INFO` | Logging level |

### Smart Environment Detection

The service automatically detects its environment:

```python
# Automatic detection
if os.getenv("AWS_LAMBDA_FUNCTION_NAME"):
    return "lambda"
elif os.getenv("PYTEST_CURRENT_TEST"):
    return "testing"  
elif os.path.exists("/.dockerenv"):
    return "container"
else:
    return "local"
```

## ğŸš€ Deployment

### AWS Lambda Deployment

```bash
# Build and deploy
./deploy-lambda.sh

# Or use the CI/CD pipeline (recommended)
git push origin main
```

### Docker Deployment

```bash
# Build image
docker build -t agentic-service .

# Run container
docker run -p 8000:8000 \
  -e OPENAI_API_KEY=your-key \
  -e S3_BUCKET_NAME=your-bucket \
  agentic-service
```

### Local Development

```bash
# With auto-reload
uvicorn src.main:app --reload --host 0.0.0.0 --port 8000

# Or
python -m src.main
```

## ğŸ† Why This Architecture Rocks

### âœ… **For New Developers**
- **Clear structure**: Know exactly where to find and add code
- **Self-documenting**: Code tells you what it does
- **Safe changes**: Isolated components mean less risk

### âœ… **For Experienced Developers**
- **Professional patterns**: Clean architecture principles
- **Extensible design**: Easy to add new features
- **Performance optimized**: Async/await throughout

### âœ… **For Operations**
- **Environment aware**: Adapts to local/container/lambda
- **Comprehensive logging**: Structured, searchable logs
- **Graceful failures**: Detailed error messages and recovery

### âœ… **For Business**
- **Fast development**: Clean code = faster features
- **Reliable**: Comprehensive testing and error handling
- **Scalable**: Cloud-native design patterns

## ğŸ“Š Performance & Metrics

| Metric | Value | Description |
|--------|-------|-------------|
| **Code Reduction** | 84% | From 961-line monolith to 150-line controller |
| **Modularity** | 12x | From 1 giant file to 12 focused modules |
| **Test Coverage** | >90% | Comprehensive test suite |
| **Cold Start** | <2s | Lambda optimization |
| **Processing Speed** | ~100ms/page | PDF processing performance |

## ğŸ› Troubleshooting

### Common Issues

#### 1. **OpenAI API Errors**
```bash
# Check API key
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
  https://api.openai.com/v1/models
```

#### 2. **AWS Connectivity**
```bash
# Test S3 access
aws s3 ls s3://your-bucket-name

# Test credentials
aws sts get-caller-identity
```

#### 3. **Local Development Issues**
```bash
# Check environment
python -c "from src.config import config; print(f'Environment: {config.ENVIRONMENT}')"

# Validate config
python -c "from src.config import config; print(config.validate_config())"
```

#### 4. **Import Errors**
```bash
# Check Python path
export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"

# Or use relative imports
python -m src.main
```

## ğŸ¤ Contributing

### Development Workflow

1. **Fork & Branch**
```bash
git checkout -b feature/amazing-new-feature
```

2. **Make Changes**
- Follow the existing architecture patterns
- Add tests for new functionality
- Update documentation

3. **Test Everything**
```bash
pytest --cov=src
black src/
flake8 src/
```

4. **Submit PR**
- Clear description of changes
- Include test results
- Update README if needed

### Code Style

- **Black** formatting
- **Type hints** everywhere
- **Docstrings** for all public functions
- **Error handling** with custom exceptions

## ğŸ“œ License

This project is part of the Pathlight platform. See the main repository for license information.

---

## ğŸ¯ Ready to Build Something Amazing?

This service provides a rock-solid foundation for document processing and AI-powered search. The clean architecture makes it easy to:

- ğŸ”§ **Extend**: Add new file types, AI services, or storage backends
- ğŸ§ª **Test**: Isolated components are easy to test
- ğŸš€ **Deploy**: Multiple deployment options (local, container, serverless)
- ğŸ“ˆ **Scale**: Cloud-native design patterns

**Happy coding!** ğŸš€

---

*Built with â¤ï¸ by the Pathlight team*
